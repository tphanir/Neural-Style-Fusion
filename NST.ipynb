{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tphanir/NeuralStyleFusion/blob/main/NST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRIOR INSTALLATION**"
      ],
      "metadata": {
        "id": "LCP_pADMo8b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy matplotlib"
      ],
      "metadata": {
        "id": "KPnxeJunon5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUqh5QJFKERz"
      },
      "source": [
        "**IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLNv1q22QeaD"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WDem-LLGzb"
      },
      "source": [
        "**FUNCTION TO CONVERT AN IMAGE TO A TENSOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENgsgzZhQxE0"
      },
      "outputs": [],
      "source": [
        "def imageToTensor(image):\n",
        "  size = 400\n",
        "  image = Image.open(image)\n",
        "\n",
        "  im_size = size\n",
        "\n",
        "  in_transform = transforms.Compose([\n",
        "      transforms.Resize((im_size, im_size)),\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "\n",
        "  image = in_transform(image).unsqueeze(0)\n",
        "\n",
        "  return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeN1KPdOLMI3"
      },
      "source": [
        "**FUNCTION TO CONVERT A TENSOR TO AN IMAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXVvDgbhR-7g"
      },
      "outputs": [],
      "source": [
        "def tensorToImage(tensor):\n",
        "  image = tensor.to(\"cpu\").clone().detach()\n",
        "  image = image.squeeze()\n",
        "  image = torch.permute(image,(1, 2, 0))\n",
        "  image = image.numpy()\n",
        "  image = image.clip(0,1)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_frRdY4sLaDF"
      },
      "source": [
        "**FUNCTION TO EXTRACT FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0Ut0xvASbqL"
      },
      "outputs": [],
      "source": [
        "def get_features(image, model):\n",
        "  layers = {\n",
        "        '0' : 'conv1_1',\n",
        "        '5' : 'conv2_1',\n",
        "        '10' : 'conv3_1',\n",
        "        '19' : 'conv4_1',\n",
        "        '21' : 'conv4_2',\n",
        "        '28' : 'conv5_1'\n",
        "    }\n",
        "\n",
        "  features = {}\n",
        "  x = image\n",
        "  for name, layer in enumerate(model):\n",
        "    x = layer(x)\n",
        "    if str(name) in layers:\n",
        "      features[layers[str(name)]] = x\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XdFR-GMxjf"
      },
      "source": [
        "**FUNCTION FOR GRAM MATRIX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhYUKgWHTRsi"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(tensor):\n",
        "  _, n_c, n_h, n_w = tensor.size()\n",
        "  tensor = tensor.view(n_c, n_h * n_w)\n",
        "  g = torch.mm(tensor, tensor.t())\n",
        "  return g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpDPhvfXNBW0"
      },
      "source": [
        "**SETTING UP THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIoqxm0GDiCj"
      },
      "outputs": [],
      "source": [
        "vgg = models.vgg19(pretrained=True).features.to(\"cuda:0\")\n",
        "for params in vgg.parameters():\n",
        "  params.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvU-ow5-NNtL"
      },
      "source": [
        "**LOADING THE IMAGES AND FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5DFFpQ0DlTJ"
      },
      "outputs": [],
      "source": [
        "content = imageToTensor(\"content.jpeg\").to(\"cuda:0\")\n",
        "style = imageToTensor(\"style.jpg\").to(\"cuda:0\")\n",
        "\n",
        "content_features = get_features(content, vgg)\n",
        "style_features = get_features(style, vgg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBOknWciNYYR"
      },
      "source": [
        "**COMPUTING GRAM MATRIX FOR STYLE IMAGE FOR ALL STYLE LAYERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y5Cnn9vEjLf"
      },
      "outputs": [],
      "source": [
        "gm = {}\n",
        "\n",
        "for layer in style_features:\n",
        "  gm[layer] = gram_matrix(style_features[layer])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GENERATING A RANDOM IMAGE**"
      ],
      "metadata": {
        "id": "9D0Y5yZmGWto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwDXDNMhE30i"
      },
      "outputs": [],
      "source": [
        "G1 = content.clone().to(\"cuda:0\")\n",
        "G = G1.clone().requires_grad_(True).to(\"cuda:0\")\n",
        "G.is_leaf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STYLE WEIGHTS**"
      ],
      "metadata": {
        "id": "iLpeRlnwGczQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltHGUWffFB-K"
      },
      "outputs": [],
      "source": [
        "style_weights = {'conv1_1': 0.85,\n",
        "                 'conv2_1': 0.56,\n",
        "                 'conv3_1': 0.11,\n",
        "                 'conv4_1': 0.15,\n",
        "                 'conv5_1': 0.2}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PARAMETERS**"
      ],
      "metadata": {
        "id": "ibKCLTJ1Ge0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGF9uKn_Fv85"
      },
      "outputs": [],
      "source": [
        "alpha = 100\n",
        "beta = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADAM OPTIMIZER**"
      ],
      "metadata": {
        "id": "RlO61xlPGvBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJWenWqVFydz"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([G], lr=0.02)\n",
        "loss = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING LOOP**"
      ],
      "metadata": {
        "id": "3vnbiZYTGskU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jenBELwF1Hp"
      },
      "outputs": [],
      "source": [
        "for i in range(2000):\n",
        "  target_features = get_features(G,vgg)\n",
        "  _, n_c, n_w, n_h = target_features['conv4_2'].shape\n",
        "\n",
        "  content_loss = loss(target_features['conv4_2'], content_features['conv4_2'])\n",
        "\n",
        "  style_loss = 0\n",
        "\n",
        "  for layer in style_weights:\n",
        "    target_feature = target_features[layer]\n",
        "    target_gram = gram_matrix(target_feature)\n",
        "    style_gram = gm[layer]\n",
        "\n",
        "    layer_style_loss = style_weights[layer] * loss(target_gram, style_gram)\n",
        "    style_loss += layer_style_loss\n",
        "\n",
        "  total_loss =  alpha * content_loss + beta * style_loss\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%200==0:\n",
        "    print(total_loss.item())\n",
        "    plt.imshow(tensorToImage(G))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVING THE GENERATED IMAGE**"
      ],
      "metadata": {
        "id": "MXHLVrkAsMI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = tensorToImage(G)\n",
        "plt.imshow(out)\n",
        "plt.axis(\"off\")\n",
        "plt.savefig('generated')"
      ],
      "metadata": {
        "id": "iD7AcHvFqn2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhC4lN6mD30qD5uiXYjyY8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}